{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F_I0QZE8SvxQ",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qk_4Xk2pUacs"
      },
      "outputs": [],
      "source": [
        "!python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Am-ECbfpUcZp"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import copy\n",
        "import shutil\n",
        "import logging\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from datetime import datetime\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Detectron2\n",
        "from detectron2.data.datasets import register_coco_instances\n",
        "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
        "from detectron2.utils.visualizer import Visualizer\n",
        "from detectron2.utils.visualizer import ColorMode\n",
        "from detectron2 import model_zoo\n",
        "from detectron2.config import get_cfg\n",
        "from detectron2.engine import DefaultPredictor\n",
        "from detectron2.evaluation import COCOEvaluator\n",
        "from detectron2.engine import DefaultTrainer\n",
        "from detectron2.engine.hooks import HookBase\n",
        "from detectron2.evaluation import inference_context\n",
        "from detectron2.utils.logger import log_every_n_seconds\n",
        "from detectron2.data import DatasetMapper, build_detection_test_loader\n",
        "import detectron2.utils.comm as comm\n",
        "\n",
        "# Metryki\n",
        "import torch\n",
        "from torchvision.ops import box_iou\n",
        "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
        "\n",
        "import time\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pa0fvFX0YZTD"
      },
      "outputs": [],
      "source": [
        "!pip install roboflow\n",
        "ROBOFLOW_API_KEY=\"XXXXXXXX\"\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=ROBOFLOW_API_KEY)\n",
        "project = rf.workspace(\"roboflow-jvuqo\").project(\"football-ball-detection-rejhg\")\n",
        "version = project.version(1)\n",
        "dataset = version.download(\"coco\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiaBNmfWhMnz"
      },
      "outputs": [],
      "source": [
        "DATA_SET_NAME = \"football-ball-detection\"\n",
        "FILTERED_DIR = \"./filtered_ball_only\"\n",
        "os.makedirs(FILTERED_DIR, exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jc2Ls4HlhUnx",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "for split in ['train', 'valid', 'test']:\n",
        "    input_json = os.path.join(dataset.location, split, \"_annotations.coco.json\")\n",
        "    output_json = os.path.join(FILTERED_DIR, f\"{split}_ball_only.json\")\n",
        "\n",
        "    print(f\"Processing split: {split}\")\n",
        "\n",
        "    if not os.path.exists(input_json):\n",
        "        print(f\"File not found: {input_json}\")\n",
        "        continue\n",
        "\n",
        "    with open(input_json, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    ball_keywords = ['ball']\n",
        "    ball_cat_ids = []\n",
        "\n",
        "    for cat in data.get('categories', []):\n",
        "        cat_name_lower = cat['name'].lower()\n",
        "        if any(keyword in cat_name_lower for keyword in ball_keywords):\n",
        "            ball_cat_ids.append(cat['id'])\n",
        "\n",
        "    if not ball_cat_ids:\n",
        "        print(f\"No 'ball' category found in {split}!\")\n",
        "        if len(data.get('categories', [])) == 1:\n",
        "            ball_cat_ids = [data['categories'][0]['id']]\n",
        "            print(f\"Using the only available category: ID={ball_cat_ids[0]}\")\n",
        "\n",
        "    all_annotations = data.get('annotations', [])\n",
        "    new_annotations = []\n",
        "    for ann in all_annotations:\n",
        "        if ann['category_id'] in ball_cat_ids:\n",
        "            ann_copy = ann.copy()\n",
        "            ann_copy['category_id'] = 0\n",
        "            new_annotations.append(ann_copy)\n",
        "\n",
        "    images_with_ball = set(ann['image_id'] for ann in new_annotations)\n",
        "    all_images = data.get('images', [])\n",
        "    new_images = [img for img in all_images if img['id'] in images_with_ball]\n",
        "\n",
        "    filtered_data = {\n",
        "        'info': data.get('info', {}),\n",
        "        'licenses': data.get('licenses', []),\n",
        "        'categories': [{'id': 0, 'name': 'ball', 'supercategory': 'none'}],\n",
        "        'images': new_images,\n",
        "        'annotations': new_annotations\n",
        "    }\n",
        "\n",
        "    os.makedirs(os.path.dirname(output_json), exist_ok=True)\n",
        "    with open(output_json, 'w') as f:\n",
        "        json.dump(filtered_data, f, indent=2)\n",
        "\n",
        "    if len(new_annotations) == 0:\n",
        "        print(f\"Warning: {split} has 0 balls after filtering!\")\n",
        "    else:\n",
        "        print(f\"Saved filtered data for {split} to: {output_json}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WsfiPh4dYf0A",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "for ds_name in [f\"{DATA_SET_NAME}-ball-train\", f\"{DATA_SET_NAME}-ball-test\", f\"{DATA_SET_NAME}-ball-valid\"]:\n",
        "    if ds_name in DatasetCatalog:\n",
        "        DatasetCatalog.remove(ds_name)\n",
        "    if ds_name in MetadataCatalog:\n",
        "        MetadataCatalog.remove(ds_name)\n",
        "\n",
        "TRAIN_DATA_SET_NAME = f\"{DATA_SET_NAME}-ball-train\"\n",
        "train_json = os.path.join(FILTERED_DIR, \"train_ball_only.json\")\n",
        "train_images = os.path.join(dataset.location, \"train\")\n",
        "\n",
        "if os.path.exists(train_json):\n",
        "    register_coco_instances(\n",
        "        name=TRAIN_DATA_SET_NAME,\n",
        "        metadata={},\n",
        "        json_file=train_json,\n",
        "        image_root=train_images\n",
        "    )\n",
        "    print(f\"Registered: {TRAIN_DATA_SET_NAME}\")\n",
        "else:\n",
        "    print(f\"File not found: {train_json}\")\n",
        "\n",
        "VALID_DATA_SET_NAME = f\"{DATA_SET_NAME}-ball-valid\"\n",
        "valid_json = os.path.join(FILTERED_DIR, \"valid_ball_only.json\")\n",
        "valid_images = os.path.join(dataset.location, \"valid\")\n",
        "\n",
        "if os.path.exists(valid_json):\n",
        "    register_coco_instances(\n",
        "        name=VALID_DATA_SET_NAME,\n",
        "        metadata={},\n",
        "        json_file=valid_json,\n",
        "        image_root=valid_images\n",
        "    )\n",
        "    print(f\"Registered: {VALID_DATA_SET_NAME}\")\n",
        "else:\n",
        "    print(f\"File not found: {valid_json}\")\n",
        "\n",
        "TEST_DATA_SET_NAME = f\"{DATA_SET_NAME}-ball-test\"\n",
        "test_json = os.path.join(FILTERED_DIR, \"test_ball_only.json\")\n",
        "test_images = os.path.join(dataset.location, \"test\")\n",
        "\n",
        "if os.path.exists(test_json):\n",
        "    register_coco_instances(\n",
        "        name=TEST_DATA_SET_NAME,\n",
        "        metadata={},\n",
        "        json_file=test_json,\n",
        "        image_root=test_images\n",
        "    )\n",
        "    print(f\"Registered: {TEST_DATA_SET_NAME}\")\n",
        "else:\n",
        "    print(f\"File not found: {test_json}\")\n",
        "\n",
        "MetadataCatalog.get(TRAIN_DATA_SET_NAME).thing_classes = [\"ball\"]\n",
        "MetadataCatalog.get(VALID_DATA_SET_NAME).thing_classes = [\"ball\"]\n",
        "MetadataCatalog.get(TEST_DATA_SET_NAME).thing_classes = [\"ball\"]\n",
        "\n",
        "print(\"\\n--- Dataset Summary ---\")\n",
        "\n",
        "for name in [TRAIN_DATA_SET_NAME, VALID_DATA_SET_NAME, TEST_DATA_SET_NAME]:\n",
        "    try:\n",
        "        dataset_dicts = DatasetCatalog.get(name)\n",
        "        metadata = MetadataCatalog.get(name)\n",
        "\n",
        "        ball_count = sum(len(d.get('annotations', [])) for d in dataset_dicts)\n",
        "        images_with_balls = sum(1 for d in dataset_dicts if len(d.get('annotations', [])) > 0)\n",
        "\n",
        "        print(f\"\\nDataset: {name}\")\n",
        "        print(f\"  Classes: {metadata.thing_classes}\")\n",
        "        print(f\"  Total images: {len(dataset_dicts)}\")\n",
        "        print(f\"  Images with balls: {images_with_balls}\")\n",
        "        print(f\"  Total ball annotations: {ball_count}\")\n",
        "\n",
        "        if ball_count == 0:\n",
        "            print(f\"  WARNING: NO BALLS FOUND IN THIS DATASET!\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"\\nError for {name}: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tpej1jhoYk6f"
      },
      "outputs": [],
      "source": [
        "ARCHITECTURE = \"retinanet_R_50_FPN_3x\"\n",
        "CONFIG_FILE_PATH = f\"COCO-Detection/{ARCHITECTURE}.yaml\"\n",
        "MAX_ITER = 1800\n",
        "EVAL_PERIOD = 100\n",
        "BASE_LR = 0.001\n",
        "NUM_CLASSES = 1\n",
        "\n",
        "OUTPUT_DIR_PATH = os.path.join(\n",
        "    \"ball_only_model\",\n",
        "    ARCHITECTURE,\n",
        "    datetime.datetime.now().strftime('%Y-%m-%d-%H-%M-%S')\n",
        ")\n",
        "os.makedirs(OUTPUT_DIR_PATH, exist_ok=True)\n",
        "\n",
        "cfg = get_cfg()\n",
        "cfg.merge_from_file(model_zoo.get_config_file(CONFIG_FILE_PATH))\n",
        "cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(CONFIG_FILE_PATH)\n",
        "cfg.DATASETS.TRAIN = (TRAIN_DATA_SET_NAME,)\n",
        "cfg.DATASETS.TEST = (VALID_DATA_SET_NAME,)\n",
        "cfg.TEST.EVAL_PERIOD = EVAL_PERIOD\n",
        "cfg.DATALOADER.NUM_WORKERS = 2\n",
        "cfg.SOLVER.IMS_PER_BATCH = 5\n",
        "cfg.SOLVER.BASE_LR = BASE_LR\n",
        "cfg.SOLVER.MAX_ITER = MAX_ITER\n",
        "cfg.INPUT.MIN_SIZE_TRAIN = (1080,)\n",
        "cfg.INPUT.MAX_SIZE_TRAIN = 1920\n",
        "cfg.INPUT.MIN_SIZE_TEST = 1080\n",
        "cfg.INPUT.MAX_SIZE_TEST = 1920\n",
        "cfg.SOLVER.WARMUP_ITERS = 200\n",
        "cfg.SOLVER.WEIGHT_DECAY = 0.0001\n",
        "cfg.MODEL.RETINANET.NUM_CLASSES = NUM_CLASSES\n",
        "cfg.MODEL.RETINANET.DETECTIONS_PER_IMAGE = 1\n",
        "cfg.TEST.DETECTIONS_PER_IMAGE = 1\n",
        "\n",
        "cfg.MODEL.ANCHOR_GENERATOR.SIZES = [[6,8, 10, 12, 16, 20, 24]]\n",
        "cfg.MODEL.ANCHOR_GENERATOR.ASPECT_RATIOS = [[0.5, 0.7, 1.0, 1.5]]\n",
        "\n",
        "cfg.OUTPUT_DIR = OUTPUT_DIR_PATH"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kr_zAO0gYocj"
      },
      "outputs": [],
      "source": [
        "class LossEvalHook(HookBase):\n",
        "    def __init__(self, eval_period, model, data_loader):\n",
        "        self._model = model\n",
        "        self._period = eval_period\n",
        "        self._data_loader = data_loader\n",
        "\n",
        "    def _do_loss_eval(self):\n",
        "        total = len(self._data_loader)\n",
        "        num_warmup = min(5, total - 1)\n",
        "        start_time = time.perf_counter()\n",
        "        total_compute_time = 0\n",
        "        losses = []\n",
        "\n",
        "        for idx, inputs in enumerate(self._data_loader):\n",
        "            if idx == num_warmup:\n",
        "                start_time = time.perf_counter()\n",
        "                total_compute_time = 0\n",
        "            start_compute_time = time.perf_counter()\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.synchronize()\n",
        "            total_compute_time += time.perf_counter() - start_compute_time\n",
        "            loss_batch = self._get_loss(inputs)\n",
        "            losses.append(loss_batch)\n",
        "\n",
        "        mean_loss = np.mean(losses)\n",
        "        self.trainer.storage.put_scalar('validation_loss', mean_loss)\n",
        "        comm.synchronize()\n",
        "\n",
        "    def _get_loss(self, data):\n",
        "        metrics_dict = self._model(data)\n",
        "        metrics_dict = {\n",
        "            k: v.detach().cpu().item() if isinstance(v, torch.Tensor) else float(v)\n",
        "            for k, v in metrics_dict.items()\n",
        "        }\n",
        "        total_losses_reduced = sum(loss for loss in metrics_dict.values())\n",
        "        return total_losses_reduced\n",
        "\n",
        "    def after_step(self):\n",
        "        next_iter = self.trainer.iter + 1\n",
        "        is_final = next_iter == self.trainer.max_iter\n",
        "        if is_final or (self._period > 0 and next_iter % self._period == 0):\n",
        "            self._do_loss_eval()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ofkB575pYrQL"
      },
      "outputs": [],
      "source": [
        "class MyTrainer(DefaultTrainer):\n",
        "    @classmethod\n",
        "    def build_evaluator(cls, cfg, dataset_name, output_folder=None):\n",
        "        if output_folder is None:\n",
        "            output_folder = os.path.join(cfg.OUTPUT_DIR, \"inference\")\n",
        "        return COCOEvaluator(dataset_name, cfg, True, output_folder)\n",
        "\n",
        "    def build_hooks(self):\n",
        "        hooks = super().build_hooks()\n",
        "        hooks.insert(-1, LossEvalHook(\n",
        "            cfg.TEST.EVAL_PERIOD,\n",
        "            self.model,\n",
        "            build_detection_test_loader(\n",
        "                self.cfg,\n",
        "                self.cfg.DATASETS.TEST[0],\n",
        "                DatasetMapper(self.cfg, True)\n",
        "            )\n",
        "        ))\n",
        "        return hooks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WkS2R-HBYtaV"
      },
      "outputs": [],
      "source": [
        "trainer = MyTrainer(cfg)\n",
        "trainer.resume_or_load(resume=False)\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jc2LsHlhUnx"
      },
      "source": [
        "for split in ['train', 'valid', 'test']:\n",
        "    input_json = os.path.join(dataset.location, split, \"_annotations.coco.json\")\n",
        "    output_json = os.path.join(FILTERED_DIR, f\"{split}_ball_only.json\")\n",
        "\n",
        "    print(f\"Processing split: {split}\")\n",
        "\n",
        "    if not os.path.exists(input_json):\n",
        "        print(f\"File not found: {input_json}\")\n",
        "        continue\n",
        "\n",
        "    with open(input_json, 'r') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    ball_keywords = ['ball', 'football', 'soccer', 'pilka', 'piÅ‚ka']\n",
        "    ball_cat_ids = []\n",
        "\n",
        "    for cat in data.get('categories', []):\n",
        "        cat_name_lower = cat['name'].lower()\n",
        "        if any(keyword in cat_name_lower for keyword in ball_keywords):\n",
        "            ball_cat_ids.append(cat['id'])\n",
        "\n",
        "    if not ball_cat_ids:\n",
        "        print(f\"No 'ball' category found in {split}!\")\n",
        "        if len(data.get('categories', [])) == 1:\n",
        "            ball_cat_ids = [data['categories'][0]['id']]\n",
        "            print(f\"Using the only available category: ID={ball_cat_ids[0]}\")\n",
        "\n",
        "    all_annotations = data.get('annotations', [])\n",
        "    new_annotations = []\n",
        "    for ann in all_annotations:\n",
        "        if ann['category_id'] in ball_cat_ids:\n",
        "            ann_copy = ann.copy()\n",
        "            ann_copy['category_id'] = 0\n",
        "            new_annotations.append(ann_copy)\n",
        "\n",
        "    images_with_ball = set(ann['image_id'] for ann in new_annotations)\n",
        "    all_images = data.get('images', [])\n",
        "    new_images = [img for img in all_images if img['id'] in images_with_ball]\n",
        "\n",
        "    filtered_data = {\n",
        "        'info': data.get('info', {}),\n",
        "        'licenses': data.get('licenses', []),\n",
        "        'categories': [{'id': 0, 'name': 'ball', 'supercategory': 'none'}],\n",
        "        'images': new_images,\n",
        "        'annotations': new_annotations\n",
        "    }\n",
        "\n",
        "    os.makedirs(os.path.dirname(output_json), exist_ok=True)\n",
        "    with open(output_json, 'w') as f:\n",
        "        json.dump(filtered_data, f, indent=2)\n",
        "\n",
        "    if len(new_annotations) == 0:\n",
        "        print(f\"Warning: {split} has 0 balls after filtering!\")\n",
        "    else:\n",
        "        print(f\"Saved filtered data for {split} to: {output_json}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYp5xNaNYvmo"
      },
      "outputs": [],
      "source": [
        "cfg.MODEL.WEIGHTS = os.path.join(cfg.OUTPUT_DIR, \"model_final.pth\")\n",
        "cfg.MODEL.RETINANET.SCORE_THRESH_TEST = 0.3\n",
        "cfg.MODEL.RETINANET.NMS_THRESH_TEST = 0.4\n",
        "predictor = DefaultPredictor(cfg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5BMIZ3L6YyQw"
      },
      "outputs": [],
      "source": [
        "def evaluate_ball_detection(predictor, dataset_name, iou_threshold=0.5, conf_threshold=0.3):\n",
        "    dataset_dicts = DatasetCatalog.get(dataset_name)\n",
        "\n",
        "    all_gt_boxes = []\n",
        "    all_pred_boxes = []\n",
        "    all_pred_scores = []\n",
        "\n",
        "    y_true_images = []\n",
        "    y_pred_images = []\n",
        "\n",
        "    TP = 0\n",
        "    FP = 0\n",
        "    FN = 0\n",
        "\n",
        "    print(f\"Evaluating on {len(dataset_dicts)} images...\")\n",
        "\n",
        "    for idx, d in enumerate(dataset_dicts):\n",
        "        img = cv2.imread(d[\"file_name\"])\n",
        "        outputs = predictor(img)\n",
        "        instances = outputs[\"instances\"].to(\"cpu\")\n",
        "\n",
        "        pred_boxes = instances.pred_boxes.tensor.numpy()\n",
        "        pred_scores = instances.scores.numpy()\n",
        "\n",
        "        mask = pred_scores >= conf_threshold\n",
        "        pred_boxes = pred_boxes[mask]\n",
        "        pred_scores = pred_scores[mask]\n",
        "\n",
        "        gt_boxes = []\n",
        "        for anno in d[\"annotations\"]:\n",
        "            bbox = anno[\"bbox\"]\n",
        "            x, y, w, h = bbox\n",
        "            gt_boxes.append([x, y, x+w, y+h])\n",
        "        gt_boxes = np.array(gt_boxes)\n",
        "\n",
        "        has_gt = len(gt_boxes) > 0\n",
        "        has_pred = len(pred_boxes) > 0\n",
        "        y_true_images.append(1 if has_gt else 0)\n",
        "        y_pred_images.append(1 if has_pred else 0)\n",
        "\n",
        "        if len(pred_boxes) > 0 and len(gt_boxes) > 0:\n",
        "            ious = box_iou(torch.tensor(pred_boxes), torch.tensor(gt_boxes)).numpy()\n",
        "\n",
        "            matched_gt = set()\n",
        "            for pred_idx in range(len(pred_boxes)):\n",
        "                best_gt_idx = np.argmax(ious[pred_idx])\n",
        "                best_iou = ious[pred_idx, best_gt_idx]\n",
        "\n",
        "                if best_iou >= iou_threshold and best_gt_idx not in matched_gt:\n",
        "                    TP += 1\n",
        "                    matched_gt.add(best_gt_idx)\n",
        "                else:\n",
        "                    FP += 1\n",
        "\n",
        "            FN += len(gt_boxes) - len(matched_gt)\n",
        "\n",
        "        elif len(pred_boxes) > 0:\n",
        "            FP += len(pred_boxes)\n",
        "\n",
        "        elif len(gt_boxes) > 0:\n",
        "            FN += len(gt_boxes)\n",
        "\n",
        "        if (idx + 1) % 50 == 0:\n",
        "            print(f\"  Processed {idx + 1}/{len(dataset_dicts)} images...\")\n",
        "\n",
        "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
        "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
        "    f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "    cm = confusion_matrix(y_true_images, y_pred_images)\n",
        "\n",
        "    print(\"\\n--- Evaluation Results - Ball Detection ---\")\n",
        "    print(f\"\\nBounding Box Metrics (IoU={iou_threshold}):\")\n",
        "    print(f\"  True Positives (TP):  {TP}\")\n",
        "    print(f\"  False Positives (FP): {FP}\")\n",
        "    print(f\"  False Negatives (FN): {FN}\")\n",
        "    print(f\"\\n  Precision: {precision:.4f}\")\n",
        "    print(f\"  Recall:    {recall:.4f}\")\n",
        "    print(f\"  F1 Score:  {f1:.4f}\")\n",
        "\n",
        "    print(f\"\\nConfusion Matrix (Image-level - ball detected):\")\n",
        "    print(f\"  TN (no ball, not detected): {cm[0,0]}\")\n",
        "    print(f\"  FP (no ball, detected):     {cm[0,1]}\")\n",
        "    print(f\"  FN (ball present, not detected): {cm[1,0]}\")\n",
        "    print(f\"  TP (ball present, detected):   {cm[1,1]}\")\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=['Not Detected', 'Detected'],\n",
        "                yticklabels=['No Ball', 'Ball Present'])\n",
        "    plt.ylabel('Ground Truth')\n",
        "    plt.xlabel('Prediction')\n",
        "    plt.title('Confusion Matrix - Ball Detection (Image-level)')\n",
        "    plt.tight_layout()\n",
        "\n",
        "    save_path = os.path.join(cfg.OUTPUT_DIR, \"confusion_matrix.png\")\n",
        "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    print(f\"\\nConfusion matrix saved to: {save_path}\")\n",
        "    plt.show()\n",
        "\n",
        "    return {\n",
        "        'TP': TP, 'FP': FP, 'FN': FN,\n",
        "        'precision': precision,\n",
        "        'recall': recall,\n",
        "        'f1': f1,\n",
        "        'confusion_matrix': cm\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "plS6iHjMY2vC"
      },
      "outputs": [],
      "source": [
        "results = evaluate_ball_detection(\n",
        "    predictor,\n",
        "    VALID_DATA_SET_NAME,\n",
        "    iou_threshold=0.5,\n",
        "    conf_threshold=0.3\n",
        ")\n",
        "\n",
        "results_file = os.path.join(cfg.OUTPUT_DIR, \"evaluation_results.json\")\n",
        "with open(results_file, 'w') as f:\n",
        "    json.dump({\n",
        "        'TP': int(results['TP']),\n",
        "        'FP': int(results['FP']),\n",
        "        'FN': int(results['FN']),\n",
        "        'precision': float(results['precision']),\n",
        "        'recall': float(results['recall']),\n",
        "        'f1': float(results['f1'])\n",
        "    }, f, indent=2)\n",
        "\n",
        "print(f\"Evaluation results saved to: {results_file}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}